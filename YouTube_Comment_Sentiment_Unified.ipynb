{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac0805d",
   "metadata": {},
   "source": [
    "# Unified Pipeline — Baseline + Active Learning (TF-IDF + Logistic Regression)\n",
    "이 노트북 하나에서 **베이스라인 선택**과 **Active Learning 라운드**를 모두 수행합니다.\n",
    "\n",
    "**순서**\n",
    "1) Baseline: stratified split → Calibration/τ/grid로 valid에서 베스트 선택\n",
    "2) train+valid 재학습 → test 1회 평가 → artifacts 저장\n",
    "3) Active Learning: 후보 추출 → 수동 라벨 CSV → 병합(골드 우선, 약라벨 다운샘플)\n",
    "4) (선택) 배치 추론/chi² n-gram 내보내기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q scikit-learn pandas numpy joblib\n",
    "import os, warnings, numpy as np, pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sentiment_utils import (\n",
    "    clean, ensure_cols, load_dataset, split_train_valid_test,\n",
    "    ClassicCfg, ClassicSentiment, apply_neutral_policy, small_grid_search,\n",
    "    select_active_learning_candidates, merge_gold_and_weak,\n",
    "    batch_predict, chi2_top_ngrams_from_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DATA_LABELED_BASE = 'comments_labeled.csv'        # 초기 라벨(약라벨 포함 가능)\n",
    "    DATA_LABELED_MERGED = 'comments_labeled_merged.csv'  # 라운드 후 병합본(없으면 BASE 사용)\n",
    "    LABELS = ['neg','neu','pos']\n",
    "    TEST_SIZE = 0.1\n",
    "    VALID_SIZE = 0.1\n",
    "    RANDOM_STATE = 42\n",
    "    ART_DIR = 'artifacts/classic'\n",
    "    EXPORT_DIR = 'exports_ngrams'\n",
    "    NEW_CSV = 'comments_new.csv'   # 후보 추출/배치 추론용\n",
    "\n",
    "os.makedirs(CFG.ART_DIR, exist_ok=True)\n",
    "os.makedirs(CFG.EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# 학습용 입력 데이터 선택\n",
    "DATA_FOR_TRAIN = CFG.DATA_LABELED_MERGED if os.path.exists(CFG.DATA_LABELED_MERGED) else CFG.DATA_LABELED_BASE\n",
    "print('Using training dataset:', DATA_FOR_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222a823",
   "metadata": {},
   "source": [
    "## (1) Baseline — split → grid/Calibration/τ on valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(DATA_FOR_TRAIN, labels=CFG.LABELS)\n",
    "train_df, valid_df, test_df = split_train_valid_test(df, CFG.TEST_SIZE, CFG.VALID_SIZE, CFG.RANDOM_STATE)\n",
    "print('Sizes | train:', len(train_df), 'valid:', len(valid_df), 'test:', len(test_df))\n",
    "print('Train dist:\\n', train_df['label'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "train_texts = train_df['text'].tolist()\n",
    "valid_texts = valid_df['text'].tolist()\n",
    "test_texts  = test_df['text'].tolist()\n",
    "y_train, y_valid, y_test = train_df['label'].values, valid_df['label'].values, test_df['label'].values\n",
    "\n",
    "best_cfg, best_tau, best_score = small_grid_search(train_texts, y_train, valid_texts, y_valid)\n",
    "print('Best on valid | macro-F1:', round(best_score, 4), '| cfg:', best_cfg, '| tau:', best_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fb77e",
   "metadata": {},
   "source": [
    "## (2) Retrain on train+valid → Test once → Save artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_texts = pd.concat([train_df['text'], valid_df['text']]).tolist()\n",
    "tv_labels = pd.concat([train_df['label'], valid_df['label']]).values\n",
    "\n",
    "final_model = ClassicSentiment(best_cfg).fit(tv_texts, tv_labels)\n",
    "proba_test, labels_test = final_model.predict_proba(test_texts)\n",
    "pred_test = apply_neutral_policy(proba_test, labels_test, tau=best_tau, gap=0.05)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"=== Test Report (final) ===\")\n",
    "print(classification_report(y_test, pred_test, digits=4))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred_test, labels=CFG.LABELS))\n",
    "\n",
    "final_model.save(CFG.ART_DIR)\n",
    "print('Saved artifacts to', CFG.ART_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2167f",
   "metadata": {},
   "source": [
    "## (3) Active Learning — Candidate selection → Manual CSV → Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3-1) 후보 추출: 저신뢰 p_max + k-means 다양성\n",
    "cand = select_active_learning_candidates(CFG.NEW_CSV, CFG.ART_DIR, K=50, per_cluster=4, tau_for_low=0.6)\n",
    "cand.to_csv('to_label_manual.csv', index=False, encoding='utf-8-sig')\n",
    "cand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3-2) 사람이 'to_label_manual.csv'에 label 채운 후, 아래 병합 실행\n",
    "df_merged = merge_gold_and_weak(CFG.DATA_LABELED_BASE, 'manual_labeled_round1.csv', key='comment_id', weak_frac=0.4)\n",
    "df_merged.to_csv(CFG.DATA_LABELED_MERGED, index=False, encoding='utf-8-sig')\n",
    "print('Merged saved ->', CFG.DATA_LABELED_MERGED)\n",
    "df_merged['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3ebe4",
   "metadata": {},
   "source": [
    "## (4) (선택) Batch inference & chi² n-gram exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = batch_predict(CFG.NEW_CSV, CFG.ART_DIR, tau=best_tau, gap=0.05)\n",
    "print('Pred CSV ->', out_path)\n",
    "chi2_top_ngrams_from_df(pd.read_csv(out_path, encoding='utf-8'), label_col='pred', export_dir=CFG.EXPORT_DIR)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
